# Research Instruments: agentii-kit PMF Discovery

**Feature**: 001-agentii-kit-pmf
**Created**: 2025-12-04
**Status**: Ready for Phase 1

---

## Overview

This document contains all research instruments (interview guides, usability testing scripts, survey templates) for Phases 1-3 of the agentii-kit PMF discovery research plan. All instruments are designed to collect direct customer evidence aligned with constitution principles (community-first discovery, customer-evidence-driven validation).

---

## Instrument 1: Kit Creator Interview Guide (Phase 1)

**Purpose**: Validate Kit Creator persona (Sarah - Senior PM); confirm JTBD #2 (Share My Workflow); assess willingness-to-pay

**Duration**: 45-60 min
**Format**: Remote (Zoom), recorded with consent
**Incentive**: $50 Amazon gift card

### Pre-Interview Screener

Send via Google Form or Typeform:

1. What is your current role? *(Open text)*
2. What company do you work at? What's the company stage? *(Open text)*
3. How many years of experience do you have in this role? *(Dropdown: < 1, 1-2, 3-5, 5+)*
4. Do you use AI tools (Claude, ChatGPT, Copilot) for work? *(Yes / No)*
5. Have you ever created templates or workflows for your team? *(Yes / No / Not sure)*
6. Are you comfortable with a 60-min recorded Zoom interview? *(Yes / No)*

**Qualification Criteria**: Role = PM/Marketing Lead, 3+ years experience, uses AI tools, has created templates

### Interview Script

**Opening (5 min)**

> "Hi [Name], thanks for joining! I'm researching how product managers and marketers create and share workflows. Everything we discuss today is confidential and will only be used for research purposes. I'd like to record this session so I can review it later - is that okay with you?"

*(Wait for verbal consent; start recording)*

> "Great! Before we start, tell me a bit about yourself - what do you do at [Company]?"

---

**Section 1: Role & Context (10 min)**

*Goal: Establish persona fit, tools used, success metrics*

1. "Walk me through a typical week - what are the main things you work on?"
2. "What tools do you use day-to-day?" *(Probe: Notion, Figma, GitHub, AI tools)*
3. "How do you measure success in your role?" *(Probe: Features shipped, metrics moved)*
4. "Who do you collaborate with most often?" *(Probe: Eng, Design, Marketing)*

---

**Section 2: Current Workflow for Creating Specs/Briefs (15 min)**

*Goal: Understand current workarounds; identify pain points*

5. "Think about the last time you wrote a PRD [or campaign brief]. Walk me through your process, step by step."
   - *Probe: Where do you start? Blank page, old doc, template?*
   - *Probe: What sections do you include? How do you remember what to include?*
   - *Probe: Do you use AI (Claude, ChatGPT)? How?*

6. "How long does it typically take you to write a complete PRD [or brief]?"
   - *Probe: First draft vs final version*
   - *Probe: How much time is spent on setup/structure vs actual content?*

7. "What's the most frustrating part of this process?"
   - *Probe: Blank page problem? Forgetting sections? Engineers asking clarifying questions?*

8. "Do you reuse old PRDs or templates? How do you manage them?"
   - *Probe: Copy-paste? Notion database? GitHub?*
   - *Probe: Do you share templates with teammates? How?*

---

**Section 3: Pain Frequency & Intensity (10 min)**

*Goal: Quantify pain; validate 2+ hours/week hypothesis*

9. "How often do you write PRDs [or campaign briefs]?"
   - *Probe: Weekly, monthly, quarterly?*
   - *Probe: How many active projects do you manage at once?*

10. "If you could save 2 hours per week on workflow setup, what would that mean for you?"
    - *Probe: More features shipped? Less stress? Better quality?*

11. "Have you ever looked for templates or automation for this? What did you try?"
    - *Probe: Google search, Notion templates, PromptBase, Cursor Rules, ChatGPT prompts*
    - *Probe: What did you like/dislike about those solutions?*

---

**Section 4: JTBD Validation (Share My Workflow) (10 min)**

*Goal: Assess motivation to share workflows; validate JTBD #2*

12. "Have you ever shared a workflow or template you created with others outside your team?"
    - *Probe: Blog post, Twitter, Notion template gallery, GitHub?*
    - *Probe: Why did you share it? What motivated you?*

13. "If there were an easy way to package your workflow as a reusable template and share it with a community, would that interest you? Why or why not?"
    - *Probe: Thought leadership? Helping others? Portfolio building?*
    - *Probe: What would make it worth your time?*

14. "What would you want in return for sharing your workflow?"
    - *Probe: Recognition (stars, followers)? Feedback (issues, PRs)? Money (premium kits)?*
    - *Probe: Would you maintain it over time? Why?*

---

**Section 5: Competitive Alternatives (5 min)**

*Goal: Assess incumbent awareness; identify differentiation opportunities*

15. "Have you heard of PromptBase, Fabric, or Cursor Rules repositories?"
    - *If yes: "What do you think of them? Have you used them?"*
    - *If no: "Where do you typically search for templates or workflows?"*

16. "What's missing from existing template solutions that you wish existed?"

---

**Section 6: Willingness-to-Pay (5 min)**

*Goal: Test price sensitivity; explore premium features*

17. "Imagine a marketplace for curated, GitHub-native workflow kits - like GitHub for PM/marketing templates. Would you use it?"
    - *Probe: What would make it valuable to you vs free alternatives?*

18. "If we added premium features like private kits or team accounts, would you pay for them? What feels like a reasonable price?"
    - *Probe: $0, $5/mo, $20/mo, $50/mo?*
    - *Probe: What features would you pay for? (private kits, advanced search, priority support, creator monetization)*

19. "Would you pay to be a 'featured creator' if it meant more visibility for your kits?"

---

**Closing (5 min)**

20. "Is there anything else about how you create or share workflows that I didn't ask about?"

21. "Would you be interested in testing an early version of this in a few weeks?" *(Recruit for Phase 2 usability tests)*

> "Thank you so much for your time, [Name]! I'll send you the $50 gift card within 24 hours. If you have any questions, feel free to reach out."

---

### Post-Interview Synthesis

**Tag in Notion**:
- Persona: Kit Creator (PM / Marketing Lead / Other)
- Pain frequency: [X] hours/week
- JTBD mentions: Discover ☐ / Share ☐ / Validate ☐
- Willingness-to-pay: Yes ($[X]/mo) / No / Maybe
- Incumbent mentions: PromptBase ☐ / Notion ☐ / ChatGPT ☐ / Google ☐
- Quotes: [3-5 verbatim quotes with context]

---

## Instrument 2: Kit User Interview Guide (Phase 1)

**Purpose**: Validate Kit User persona (Marcus - Growth Marketer); confirm JTBD #1 (Discover Workflows); assess willingness-to-pay

**Duration**: 45-60 min
**Format**: Remote (Zoom), recorded with consent
**Incentive**: $50 Amazon gift card

### Pre-Interview Screener

*(Same as Kit Creator screener, adjust criteria: Growth marketer or PM, 2+ years experience, uses AI for work)*

### Interview Script

**Opening (5 min)**

*(Same as Kit Creator opening)*

---

**Section 1: Role & Context (10 min)**

*(Same as Kit Creator Section 1)*

---

**Section 2: Current Workflow for Finding/Using Templates (15 min)**

*Goal: Understand discovery process; identify friction in existing solutions*

5. "Think about the last time you needed to create a [PRD / marketing campaign brief]. What was the first thing you did?"
   - *Probe: Google search? Copy old work? Ask teammate? Start from scratch?*
   - *Probe: What keywords did you search for?*

6. "When you find a template online (Notion, blog post, etc.), what do you look for before deciding to use it?"
   - *Probe: Example use case? Complete/incomplete? Last updated? Stars/likes?*
   - *Probe: Have you ever downloaded a template and found it incomplete or outdated? How did that feel?*

7. "How do you adapt templates you find to your specific needs?"
   - *Probe: Manual editing? Use with AI (ChatGPT)? Combination?*

8. "How often do you need to create new workflows or documents from scratch?"
   - *Probe: Weekly, monthly, per project?*
   - *Probe: How much time do you spend finding vs using templates?*

---

**Section 3: Pain Frequency & Intensity (10 min)**

*(Similar to Kit Creator Section 3, focus on time spent finding/adapting templates)*

9. "How much time do you spend per week finding and adapting templates or workflows?"
    - *Probe: Is it 1 hour, 2 hours, more?*
    - *Probe: What's the most time-consuming part?*

10. "If you could instantly find the perfect template for your workflow, how much time would that save you?"

11. "Have you tried PromptBase, Notion templates, or ChatGPT with custom prompts? What worked or didn't work?"
    - *Probe: Quality issues? Lack of structure? No version control?*

---

**Section 4: JTBD Validation (Discover & Validate Quality) (10 min)**

*Goal: Validate JTBD #1 (Discover) and JTBD #3 (Validate Quality)*

12. "When you're evaluating a template, what makes you trust it enough to use it?"
    - *Probe: Who created it? How many people used it? Is it complete?*
    - *Probe: Would GitHub stars/forks influence your decision? Why?*

13. "Have you ever abandoned a template mid-use because it was incomplete or low quality? Tell me about that experience."

14. "If there were a marketplace with curated, community-validated templates, how would you decide which one to try?"
    - *Probe: Browse by category? Search by keyword? Filter by stars/forks?*
    - *Probe: Would you prefer 20 high-quality options or 200 mixed-quality options?*

---

**Section 5: Competitive Alternatives (5 min)**

*(Same as Kit Creator Section 5)*

---

**Section 6: Willingness-to-Pay (5 min)**

*(Similar to Kit Creator Section 6, adjust for user perspective)*

17. "If a marketplace existed with curated, GitHub-native templates that were always up-to-date, would you use it over free alternatives like Google search or Notion?"
    - *Probe: What would make it 10x better than free options?*

18. "Would you pay for features like advanced search, private templates, or priority support? How much?"
    - *Probe: $0, $5/mo, $20/mo?*

---

**Closing (5 min)**

*(Same as Kit Creator closing)*

---

### Post-Interview Synthesis

*(Same tags as Kit Creator, adjust JTBD: Discover ☐ / Share ☐ / Validate ☐)*

---

## Instrument 3: User Workflow Usability Test Script (Phase 2)

**Purpose**: Validate Hero Workflow 1 (Discover and Fork a Kit); measure TTFW; identify friction points

**Duration**: 45 min
**Format**: Remote (Zoom), screen share + recording
**Participants**: N=10 PM/marketer personas (non-engineers)
**Incentive**: $50 Amazon gift card

### Pre-Test Setup

1. Send participant test account credentials (if needed for GitHub OAuth testing)
2. Ensure they have: Modern browser, stable internet, microphone
3. Request screen share + think-aloud protocol

### Usability Test Script

**Opening (5 min)**

> "Hi [Name], thanks for joining! Today we're testing a new workflow for finding and using templates. I'll give you a scenario and ask you to complete some tasks. Please think aloud as you work - narrate what you're doing, what you're looking for, and what's confusing. There are no wrong answers - we're testing the product, not you. Ready?"

---

**Scenario Setup (2 min)**

> "Imagine you need to write a marketing campaign brief for an upcoming product launch. You've heard about agentii-kit, a marketplace for workflow templates. Your goal is to find a relevant kit and get it set up so you can start using it."

---

**Task 1: Browse and Discover (10 min)**

*Goal: Test homepage UX; measure discovery friction*

> "I'm going to show you the agentii-kit homepage. Take a look and tell me what you see."

*(Share screen with kits.agentii.ai homepage)*

1. "What do you think this website is for?"
2. "How would you find a template for writing a marketing campaign brief?"
   - *Observe: Do they use search? Browse categories? Filters?*
   - *Friction point: Unclear navigation? Too many options? Missing category?*

3. "Pick a kit that looks relevant and click into it."
   - *Observe: What do they look for? (stars, description, last updated, example use case)*
   - *Friction point: Missing information? Unclear value prop?*

---

**Task 2: Evaluate Kit Quality (5 min)**

*Goal: Test kit detail page; validate JTBD #3 (Validate Quality)*

4. "You're now looking at the [Kit Name] detail page. What information helps you decide if this kit is worth using?"
   - *Probe: Stars/forks? Last updated? Example outputs? GitHub stats?*

5. "On a scale of 1-5, how confident are you that this kit will meet your needs?"
   - *Record rating + reason*

---

**Task 3: Fork to GitHub (15 min) - **TTFW MEASUREMENT STARTS HERE**

*Goal: Test GitHub OAuth flow; measure TTFW; identify GitHub barrier friction*

> "Okay, you've decided this kit looks good. Now your goal is to fork it to your GitHub account so you can use it. Go ahead and try to do that."

*(Start timer)*

6. "Click 'Fork to GitHub' and complete the process."
   - *Observe: Do they get stuck at GitHub OAuth? Sign up vs login?*
   - *Friction point: No GitHub account? Unclear what "fork" means? Permissions scary?*
   - *Friction point: After fork, do they know what to do next?*

7. "You've successfully forked the kit. Now what?"
   - *Observe: Do they see Quick Start guide? Do they read it?*
   - *Friction point: Unclear next steps? Missing Quick Start link?*

*(Stop timer when they've forked + understand next steps)*

---

**Task 4: Next Steps Understanding (5 min)**

*Goal: Test Quick Start guide clarity*

8. "Based on what you see, how would you actually start using this kit?"
   - *Observe: Do they understand they need to clone locally? Use with AI agent?*
   - *Friction point: Missing installation instructions? Unclear agent compatibility?*

9. "On a scale of 1-5, how easy was it to fork this kit and understand how to use it?"
   - *Record rating + reason*

---

**Post-Test Survey (5 min)**

10. **Satisfaction**: "Overall, how satisfied are you with this experience? (1-5 stars)"
11. **Ease of use**: "Was forking to GitHub easier or harder than you expected?"
12. **Friction points**: "What was the most confusing part?"
13. **Improvement**: "If you could change one thing, what would it be?"
14. **Would use**: "Would you use agentii-kit if it existed? Why or why not?"

---

**Closing (3 min)**

> "Thank you! One last question - would you recommend this to a colleague? Why or why not?"

*(Send $50 gift card within 24 hours)*

---

### Post-Test Synthesis

**Record in Notion**:
- TTFW: [X] min [Y] sec
- Completion: Success ☐ / Partial ☐ / Fail ☐
- Friction points: GitHub barrier ☐ / Unclear instructions ☐ / Missing features ☐ / Other: [specify]
- Satisfaction: [1-5 stars]
- Quotes: [2-3 verbatim reactions]
- Would recommend: Yes ☐ / No ☐ / Maybe ☐

---

## Instrument 4: Creator Workflow Usability Test Script (Phase 2)

**Purpose**: Validate Hero Workflow 2 (Submit and Share a Kit); measure submission time; test curation satisfaction

**Duration**: 45 min
**Format**: Remote (Zoom), screen share + recording
**Participants**: N=8 PM/marketer creators (have created templates before)
**Incentive**: $50 Amazon gift card

### Usability Test Script

*(Opening similar to User Workflow script)*

**Scenario Setup (2 min)**

> "Imagine you've created a PM PRD template that you want to share with the community. Your goal is to submit it to agentii-kit so others can discover and use it."

---

**Task 1: Navigate to Submission (2 min)**

> "Go to kits.agentii.ai and find where you'd submit a kit."

*(Observe: Do they find "Submit a Kit" button easily?)*

---

**Task 2: GitHub OAuth & Repo Selection (5 min)**

> "You're now on the submission page. Complete the GitHub OAuth flow and select the repo containing your kit."

*(Observe: GitHub OAuth friction? Do they understand `.specify/` requirement?)*

---

**Task 3: Fill Metadata Form (10 min) - **SUBMISSION TIME MEASUREMENT STARTS HERE**

> "Fill out the metadata form to describe your kit."

*(Start timer)*

*(Observe: Do they understand each field? Is description clear? Do they add tags?)*

**Friction points to watch**:
- Required fields unclear?
- Character limits too restrictive?
- Category dropdown missing relevant options?
- Example use case field confusing?

---

**Task 4: Preview & Submit (3 min)**

> "Preview how your kit will appear in the gallery, then submit it."

*(Stop timer at submission confirmation)*

---

**Task 5: Simulate Manual Review (10 min)**

*Goal: Test curation feedback satisfaction*

> "Your kit has been submitted and is now under review. In 24-48 hours, you'll receive feedback. Let me show you two scenarios."

**Scenario A: Rejection with Feedback**

*(Show mockup: "Your kit submission was not approved. Reason: Missing example use case. Please add one and resubmit.")*

Questions:
- "How do you feel about this feedback?"
- "Is it clear what you need to fix?"
- "On a scale of 1-5, how helpful is this feedback?"
- "Would you fix and resubmit, or give up?"

**Scenario B: Acceptance**

*(Show mockup: "Your kit is live! View your dashboard [link]. You have 5 forks and 12 stars so far.")*

Questions:
- "How do you feel about this notification?"
- "What would you do next?" *(Probe: Check dashboard? Share on Twitter? Respond to issues?)*

---

**Post-Test Survey (5 min)**

*(Similar to User Workflow survey, adjust for creator perspective)*

1. **Submission time**: "How long did it feel like it took to submit your kit?" *(Compare to actual time)*
2. **Metadata clarity**: "Was the submission form clear? Any confusing fields?"
3. **Curation feedback satisfaction**: "On a scale of 1-5, how satisfied are you with the manual review process?"
4. **Abandonment intent**: "If your kit were rejected, would you fix and resubmit or give up?"
5. **Motivation**: "What would motivate you to maintain your kit over time?" *(Stars? Feedback? Money?)*

---

**Closing (3 min)**

*(Same as User Workflow closing)*

---

### Post-Test Synthesis

**Record in Notion**:
- Submission time: [X] min [Y] sec
- Completion: Success ☐ / Partial ☐ / Fail ☐
- Metadata quality: Complete ☐ / Missing fields ☐
- Curation satisfaction: [1-5 stars]
- Abandonment intent: Would resubmit ☐ / Would give up ☐
- Quotes: [2-3 verbatim reactions]

---

## Instrument 5: Post-Session Satisfaction Survey (Phase 2)

**Purpose**: Quantitative satisfaction + friction point capture after usability tests

**Format**: Typeform or Google Form, sent immediately after test

### Survey Questions

1. **Overall satisfaction**: "How satisfied were you with this experience?" *(1-5 stars)*
2. **Ease of use**: "How easy was it to complete the workflow?" *(1-5 scale: Very difficult → Very easy)*
3. **Time perception**: "Did it feel faster or slower than you expected?" *(Much slower / Slower / About right / Faster / Much faster)*
4. **Friction point (open-ended)**: "What was the most confusing or frustrating part?"
5. **Improvement (open-ended)**: "If you could change one thing, what would it be?"
6. **Would use**: "Would you use agentii-kit if it existed?" *(Yes / No / Maybe)*
7. **Would recommend**: "Would you recommend this to a colleague?" *(Yes / No / Maybe)*
8. **Willingness-to-pay (optional)**: "If premium features existed, would you pay for them?" *(Yes / No / Maybe) + "How much?" ($0, $5/mo, $20/mo)*

---

## Instrument 6: Landing Page Waitlist Form (Phase 0)

**Purpose**: Capture demand signal; segment early adopters

**Format**: Typeform embedded on kits.agentii.ai landing page

### Waitlist Form Fields

1. **Email**: *(Required, text input)*
2. **Role**: "What best describes your role?" *(Dropdown: Product Manager / Marketing Manager / Engineer / Designer / Founder / Other)*
3. **Problem**: "What problem are you trying to solve?" *(Open text, 1-2 sentences)*
4. **Current tools**: "What tools do you currently use for workflows?" *(Open text)*
5. **Referral source**: "How did you hear about agentii-kit?" *(Dropdown: Product Hunt / Twitter / Reddit / Friend / Google / Other)*

**Success metric**: 100+ waitlist signups from organic/paid traffic (baseline demand signal)

---

## Summary: Research Instruments Alignment

| Instrument | Phase | Purpose | Traceable to |
|------------|-------|---------|--------------|
| Kit Creator Interview | Phase 1 | Validate JTBD #2 (Share), willingness-to-pay | spec.md lines 88-102, research-questions.md Q1, Q2 |
| Kit User Interview | Phase 1 | Validate JTBD #1 (Discover), willingness-to-pay | spec.md lines 72-86, research-questions.md Q1, Q2 |
| User Workflow Usability Test | Phase 2 | Validate Hero Workflow 1, TTFW < 10 min | spec.md lines 124-150, research-questions.md Q3 |
| Creator Workflow Usability Test | Phase 2 | Validate Hero Workflow 2, curation satisfaction | spec.md lines 152-182, research-questions.md Q4 |
| Post-Session Survey | Phase 2 | Quantitative satisfaction + friction points | All Phase 2 research questions |
| Landing Page Waitlist | Phase 0 | Demand validation, early adopter segmentation | research-questions.md Q2 (willingness-to-pay) |

All instruments designed to collect direct customer evidence per constitution Principle II (Community-First Discovery).
